[2026-01-27 08:43:15,515][base_trainer_accelerate.py][INFO] - ***** Running training *****
[2026-01-27 08:43:15,516][base_trainer_accelerate.py][INFO] - LR = 0.00005000
[2026-01-27 08:43:15,516][base_trainer_accelerate.py][INFO] - Weigth Decay = 0.05000000
[2026-01-27 08:43:15,517][base_trainer_accelerate.py][INFO] - Instantaneous batch size per device = 1
[2026-01-27 08:43:15,517][base_trainer_accelerate.py][INFO] - Total Batch size = 8
[2026-01-27 08:43:15,517][base_trainer_accelerate.py][INFO] - Gradient Accumulation steps = 1
[2026-01-27 08:43:15,517][base_trainer_accelerate.py][INFO] - Number of epochs = 80
[2026-01-27 08:43:15,518][base_trainer_accelerate.py][INFO] - Number of training steps per epoch = 800
[2026-01-27 08:43:15,518][base_trainer_accelerate.py][INFO] - Number of total training steps = 64000
[2026-01-27 08:43:15,518][base_trainer_accelerate.py][INFO] - Number of model parameters = 892.37M
[2026-01-27 08:43:15,519][base_trainer_accelerate.py][INFO] - Number of model trainable parameters = 588.00M
[2026-01-27 08:43:15,523][base_trainer_accelerate.py][INFO] - Resuming from checkpoint /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29
[2026-01-27 08:43:15,524][accelerate.accelerator][INFO] - Loading states from /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29
[2026-01-27 08:43:18,223][accelerate.checkpointing][INFO] - All model weights loaded successfully
[2026-01-27 08:43:21,732][accelerate.checkpointing][INFO] - All optimizer states loaded successfully
[2026-01-27 08:43:21,733][accelerate.checkpointing][INFO] - All scheduler states loaded successfully
[2026-01-27 08:43:21,733][accelerate.checkpointing][INFO] - All dataloader sampler states loaded successfully
[2026-01-27 08:43:21,737][accelerate.checkpointing][INFO] - All random states loaded successfully
[2026-01-27 08:43:21,740][accelerate.accelerator][INFO] - Loading in 0 custom states
[2026-01-27 08:43:23,637][base_trainer_accelerate.py][INFO] - Start training epoch 29, 800 iters per inner epoch. Training dtype bf16
[2026-01-27 08:43:56,927][utils.dist][INFO] - [rank: 0] Epoch: [29]  [     0/625000]  eta: 240 days, 19:03:26  lr: 0.000032  min_lr: 0.000003  loss: 0.0126 (0.0126)  local_pts_loss: 0.0092 (0.0092)  normal_loss: 0.0019 (0.0019)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0094 (0.0094)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3700 (0.3700)  time: 33.2874  data: 20.4112  max mem: 37337
[2026-01-27 08:45:48,403][utils.dist][INFO] - [rank: 0] Epoch: [29]  [    40/625000]  eta: 25 days, 12:55:45  lr: 0.000032  min_lr: 0.000003  loss: 0.0132 (0.0133)  local_pts_loss: 0.0091 (0.0092)  normal_loss: 0.0029 (0.0030)  trans_loss: 0.0000 (0.0000)  rot_loss: 0.0067 (0.0077)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4283 (0.4283)  time: 2.7412  data: 0.0004  max mem: 40340
[2026-01-27 08:47:40,162][utils.dist][INFO] - [rank: 0] Epoch: [29]  [    80/625000]  eta: 22 days, 21:43:33  lr: 0.000032  min_lr: 0.000003  loss: 0.0131 (0.0132)  local_pts_loss: 0.0092 (0.0091)  normal_loss: 0.0028 (0.0029)  trans_loss: 0.0000 (0.0000)  rot_loss: 0.0073 (0.0075)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4388 (0.4350)  time: 2.8061  data: 0.0004  max mem: 40340
[2026-01-27 08:49:30,815][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   120/625000]  eta: 21 days, 22:42:11  lr: 0.000032  min_lr: 0.000003  loss: 0.0128 (0.0131)  local_pts_loss: 0.0087 (0.0090)  normal_loss: 0.0028 (0.0029)  trans_loss: 0.0001 (0.0000)  rot_loss: 0.0069 (0.0077)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4614 (0.4434)  time: 2.7488  data: 0.0004  max mem: 40340
[2026-01-27 08:51:23,066][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   160/625000]  eta: 21 days, 12:49:37  lr: 0.000032  min_lr: 0.000003  loss: 0.0143 (0.0137)  local_pts_loss: 0.0093 (0.0091)  normal_loss: 0.0025 (0.0028)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0076 (0.0082)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4782 (0.4656)  time: 2.8114  data: 0.0004  max mem: 40340
[2026-01-27 08:53:14,989][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   200/625000]  eta: 21 days, 6:35:12  lr: 0.000032  min_lr: 0.000003  loss: 0.0152 (0.0140)  local_pts_loss: 0.0098 (0.0093)  normal_loss: 0.0026 (0.0028)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0110 (0.0088)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4716 (0.4731)  time: 2.8302  data: 0.0004  max mem: 40340
[2026-01-27 08:55:06,479][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   240/625000]  eta: 21 days, 2:05:44  lr: 0.000031  min_lr: 0.000003  loss: 0.0123 (0.0139)  local_pts_loss: 0.0087 (0.0092)  normal_loss: 0.0024 (0.0027)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0067 (0.0085)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4585 (0.4742)  time: 2.7808  data: 0.0004  max mem: 40340
[2026-01-27 08:56:58,387][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   280/625000]  eta: 20 days, 23:07:54  lr: 0.000031  min_lr: 0.000003  loss: 0.0131 (0.0137)  local_pts_loss: 0.0097 (0.0092)  normal_loss: 0.0024 (0.0027)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0064 (0.0082)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4719 (0.4737)  time: 2.8174  data: 0.0004  max mem: 40340
[2026-01-27 08:58:52,468][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   320/625000]  eta: 20 days, 22:04:27  lr: 0.000031  min_lr: 0.000003  loss: 0.0122 (0.0136)  local_pts_loss: 0.0087 (0.0092)  normal_loss: 0.0024 (0.0026)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0072 (0.0082)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4589 (0.4735)  time: 2.7862  data: 0.0004  max mem: 40340
[2026-01-27 09:00:44,966][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   360/625000]  eta: 20 days, 20:28:59  lr: 0.000031  min_lr: 0.000003  loss: 0.0124 (0.0135)  local_pts_loss: 0.0087 (0.0092)  normal_loss: 0.0022 (0.0026)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0074 (0.0081)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4533 (0.4768)  time: 2.8043  data: 0.0004  max mem: 40340
[2026-01-27 09:02:37,086][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   400/625000]  eta: 20 days, 19:02:21  lr: 0.000031  min_lr: 0.000003  loss: 0.0121 (0.0134)  local_pts_loss: 0.0087 (0.0092)  normal_loss: 0.0023 (0.0026)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0072 (0.0081)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4742 (0.4768)  time: 2.7948  data: 0.0004  max mem: 40340
[2026-01-27 09:04:29,430][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   440/625000]  eta: 20 days, 17:56:23  lr: 0.000031  min_lr: 0.000003  loss: 0.0124 (0.0133)  local_pts_loss: 0.0090 (0.0091)  normal_loss: 0.0022 (0.0026)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0068 (0.0080)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4658 (0.4762)  time: 2.8146  data: 0.0004  max mem: 40340
[2026-01-27 09:06:21,656][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   480/625000]  eta: 20 days, 16:58:33  lr: 0.000031  min_lr: 0.000003  loss: 0.0125 (0.0133)  local_pts_loss: 0.0090 (0.0091)  normal_loss: 0.0022 (0.0025)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0076 (0.0080)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4790 (0.4772)  time: 2.7989  data: 0.0004  max mem: 40340
[2026-01-27 09:08:13,686][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   520/625000]  eta: 20 days, 16:05:22  lr: 0.000031  min_lr: 0.000003  loss: 0.0122 (0.0132)  local_pts_loss: 0.0090 (0.0091)  normal_loss: 0.0021 (0.0025)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0063 (0.0079)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4597 (0.4757)  time: 2.7724  data: 0.0004  max mem: 40340
[2026-01-27 09:10:05,950][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   560/625000]  eta: 20 days, 15:23:52  lr: 0.000031  min_lr: 0.000003  loss: 0.0123 (0.0132)  local_pts_loss: 0.0090 (0.0091)  normal_loss: 0.0021 (0.0025)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0073 (0.0079)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4486 (0.4749)  time: 2.7944  data: 0.0004  max mem: 40340
[2026-01-27 09:11:58,447][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   600/625000]  eta: 20 days, 14:51:39  lr: 0.000031  min_lr: 0.000003  loss: 0.0120 (0.0131)  local_pts_loss: 0.0085 (0.0091)  normal_loss: 0.0021 (0.0024)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0073 (0.0079)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4549 (0.4739)  time: 2.8087  data: 0.0004  max mem: 40340
[2026-01-27 09:13:51,806][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   640/625000]  eta: 20 days, 14:37:14  lr: 0.000031  min_lr: 0.000003  loss: 0.0118 (0.0130)  local_pts_loss: 0.0089 (0.0091)  normal_loss: 0.0020 (0.0024)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0065 (0.0079)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4858 (0.4736)  time: 2.8315  data: 0.0004  max mem: 40340
[2026-01-27 09:15:44,204][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   680/625000]  eta: 20 days, 14:09:36  lr: 0.000031  min_lr: 0.000003  loss: 0.0119 (0.0130)  local_pts_loss: 0.0087 (0.0091)  normal_loss: 0.0020 (0.0024)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0071 (0.0078)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4555 (0.4730)  time: 2.8100  data: 0.0004  max mem: 40340
[2026-01-27 09:17:36,754][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   720/625000]  eta: 20 days, 13:47:01  lr: 0.000031  min_lr: 0.000003  loss: 0.0122 (0.0129)  local_pts_loss: 0.0091 (0.0091)  normal_loss: 0.0021 (0.0024)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0073 (0.0078)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4750 (0.4736)  time: 2.8345  data: 0.0004  max mem: 40340
[2026-01-27 09:19:29,421][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   760/625000]  eta: 20 days, 13:28:12  lr: 0.000031  min_lr: 0.000003  loss: 0.0127 (0.0129)  local_pts_loss: 0.0089 (0.0091)  normal_loss: 0.0020 (0.0024)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0079 (0.0079)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4908 (0.4757)  time: 2.8409  data: 0.0004  max mem: 40340
[2026-01-27 09:21:21,784][base_trainer_accelerate.py][INFO] - Start validation for epoch 29
[2026-01-27 09:21:28,117][utils.dist][INFO] - [rank: 0] Validation Epoch: [29]  [ 0/15]  eta: 0:01:34  loss: 0.0132 (0.0132)  local_pts_loss: 0.0103 (0.0103)  normal_loss: 0.0018 (0.0018)  trans_loss: 0.0000 (0.0000)  rot_loss: 0.0079 (0.0079)  time: 6.3310  data: 4.0254  max mem: 40340
[2026-01-27 09:21:33,398][utils.dist][INFO] - [rank: 0] Validation Epoch: [29] Total time: 0:00:11 (0.7742 s / it)
[2026-01-27 09:21:33,401][base_trainer_accelerate.py][INFO] - Validation results: loss: 0.0132 (0.0132)  local_pts_loss: 0.0103 (0.0102)  normal_loss: 0.0018 (0.0018)  trans_loss: 0.0000 (0.0000)  rot_loss: 0.0079 (0.0079)
[2026-01-27 09:21:33,404][accelerate.accelerator][INFO] - Saving current state to /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model
[2026-01-27 09:21:37,608][accelerate.checkpointing][INFO] - Model weights saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/pytorch_model.bin
[2026-01-27 09:21:43,080][accelerate.checkpointing][INFO] - Optimizer state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/optimizer.bin
[2026-01-27 09:21:43,081][accelerate.checkpointing][INFO] - Scheduler state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/scheduler.bin
[2026-01-27 09:21:43,084][accelerate.checkpointing][INFO] - Random states saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/random_states_0.pkl
[2026-01-27 09:21:43,086][base_trainer_accelerate.py][INFO] - Saved best model at epoch 29 with val_metric: 0.0132
[2026-01-27 09:21:43,089][accelerate.accelerator][INFO] - Saving current state to /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29
[2026-01-27 09:21:47,495][accelerate.checkpointing][INFO] - Model weights saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/pytorch_model.bin
[2026-01-27 09:21:52,991][accelerate.checkpointing][INFO] - Optimizer state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/optimizer.bin
[2026-01-27 09:21:52,993][accelerate.checkpointing][INFO] - Scheduler state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/scheduler.bin
[2026-01-27 09:21:52,995][accelerate.checkpointing][INFO] - Random states saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/random_states_0.pkl
[2026-01-27 09:21:52,997][base_trainer_accelerate.py][INFO] - Saved state for global step 24000
[2026-01-27 09:21:55,094][base_trainer_accelerate.py][INFO] - Start training epoch 30, 800 iters per inner epoch. Training dtype bf16
[2026-01-27 09:22:23,053][utils.dist][INFO] - [rank: 0] Epoch: [30]  [     0/625000]  eta: 202 days, 5:29:37  lr: 0.000031  min_lr: 0.000003  loss: 0.0129 (0.0129)  local_pts_loss: 0.0097 (0.0097)  normal_loss: 0.0019 (0.0019)  trans_loss: 0.0000 (0.0000)  rot_loss: 0.0083 (0.0083)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4417 (0.4417)  time: 27.9561  data: 24.6361  max mem: 38426
[2026-01-27 09:24:14,293][utils.dist][INFO] - [rank: 0] Epoch: [30]  [    40/625000]  eta: 24 days, 13:21:12  lr: 0.000031  min_lr: 0.000003  loss: 0.0130 (0.0133)  local_pts_loss: 0.0092 (0.0095)  normal_loss: 0.0019 (0.0019)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0095 (0.0094)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5017 (0.5042)  time: 2.7609  data: 0.0004  max mem: 40342
[2026-01-27 09:26:06,938][utils.dist][INFO] - [rank: 0] Epoch: [30]  [    80/625000]  eta: 22 days, 11:41:31  lr: 0.000031  min_lr: 0.000003  loss: 0.0126 (0.0131)  local_pts_loss: 0.0087 (0.0092)  normal_loss: 0.0019 (0.0020)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0078 (0.0089)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4946 (0.5065)  time: 2.8108  data: 0.0004  max mem: 40342
[2026-01-27 09:28:00,117][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   120/625000]  eta: 21 days, 19:36:32  lr: 0.000031  min_lr: 0.000003  loss: 0.0123 (0.0129)  local_pts_loss: 0.0091 (0.0091)  normal_loss: 0.0018 (0.0019)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0067 (0.0087)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4597 (0.4989)  time: 2.8378  data: 0.0004  max mem: 40342
[2026-01-27 09:29:52,229][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   160/625000]  eta: 21 days, 10:21:06  lr: 0.000031  min_lr: 0.000003  loss: 0.0119 (0.0127)  local_pts_loss: 0.0088 (0.0090)  normal_loss: 0.0019 (0.0020)  trans_loss: 0.0000 (0.0001)  rot_loss: 0.0066 (0.0084)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4428 (0.4886)  time: 2.7993  data: 0.0004  max mem: 40342
