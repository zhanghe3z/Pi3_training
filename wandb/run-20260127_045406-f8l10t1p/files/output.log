[2026-01-27 04:54:08,272][base_trainer_accelerate.py][INFO] - ***** Running training *****
[2026-01-27 04:54:08,273][base_trainer_accelerate.py][INFO] - LR = 0.00005000
[2026-01-27 04:54:08,274][base_trainer_accelerate.py][INFO] - Weigth Decay = 0.05000000
[2026-01-27 04:54:08,274][base_trainer_accelerate.py][INFO] - Instantaneous batch size per device = 1
[2026-01-27 04:54:08,274][base_trainer_accelerate.py][INFO] - Total Batch size = 8
[2026-01-27 04:54:08,274][base_trainer_accelerate.py][INFO] - Gradient Accumulation steps = 1
[2026-01-27 04:54:08,275][base_trainer_accelerate.py][INFO] - Number of epochs = 80
[2026-01-27 04:54:08,275][base_trainer_accelerate.py][INFO] - Number of training steps per epoch = 800
[2026-01-27 04:54:08,275][base_trainer_accelerate.py][INFO] - Number of total training steps = 64000
[2026-01-27 04:54:08,275][base_trainer_accelerate.py][INFO] - Number of model parameters = 892.37M
[2026-01-27 04:54:08,276][base_trainer_accelerate.py][INFO] - Number of model trainable parameters = 588.00M
[2026-01-27 04:54:08,280][base_trainer_accelerate.py][INFO] - Resuming from checkpoint /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29
[2026-01-27 04:54:08,280][accelerate.accelerator][INFO] - Loading states from /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29
[2026-01-27 04:54:10,343][accelerate.checkpointing][INFO] - All model weights loaded successfully
[2026-01-27 04:54:12,819][accelerate.checkpointing][INFO] - All optimizer states loaded successfully
[2026-01-27 04:54:12,820][accelerate.checkpointing][INFO] - All scheduler states loaded successfully
[2026-01-27 04:54:12,821][accelerate.checkpointing][INFO] - All dataloader sampler states loaded successfully
[2026-01-27 04:54:12,824][accelerate.checkpointing][INFO] - All random states loaded successfully
[2026-01-27 04:54:12,827][accelerate.accelerator][INFO] - Loading in 0 custom states
[2026-01-27 04:54:15,339][base_trainer_accelerate.py][INFO] - Start training epoch 29, 800 iters per inner epoch. Training dtype bf16
[2026-01-27 04:54:34,768][utils.dist][INFO] - [rank: 0] Epoch: [29]  [     0/625000]  eta: 140 days, 12:44:15  lr: 0.000034  min_lr: 0.000003  loss: 0.0255 (0.0255)  local_pts_loss: 0.0172 (0.0172)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0006 (0.0006)  rot_loss: 0.0196 (0.0196)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.7788 (0.7788)  time: 19.4270  data: 12.9072  max mem: 21150
[2026-01-27 04:55:36,125][utils.dist][INFO] - [rank: 0] Epoch: [29]  [    40/625000]  eta: 14 days, 6:02:06  lr: 0.000034  min_lr: 0.000003  loss: 0.0183 (0.0259)  local_pts_loss: 0.0133 (0.0154)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0003 (0.0009)  rot_loss: 0.0138 (0.0179)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3569 (0.5346)  time: 1.4977  data: 0.0003  max mem: 25277
[2026-01-27 04:56:36,770][utils.dist][INFO] - [rank: 0] Epoch: [29]  [    80/625000]  eta: 12 days, 15:04:30  lr: 0.000034  min_lr: 0.000003  loss: 0.0157 (0.0215)  local_pts_loss: 0.0125 (0.0139)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0006)  rot_loss: 0.0126 (0.0158)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3496 (0.4920)  time: 1.5367  data: 0.0004  max mem: 25277
[2026-01-27 04:57:37,578][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   120/625000]  eta: 12 days, 2:05:46  lr: 0.000034  min_lr: 0.000003  loss: 0.0184 (0.0202)  local_pts_loss: 0.0124 (0.0134)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0004 (0.0005)  rot_loss: 0.0119 (0.0149)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4500 (0.4754)  time: 1.4993  data: 0.0004  max mem: 25277
[2026-01-27 04:58:38,109][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   160/625000]  eta: 11 days, 19:15:33  lr: 0.000033  min_lr: 0.000003  loss: 0.0168 (0.0201)  local_pts_loss: 0.0134 (0.0136)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0005)  rot_loss: 0.0096 (0.0146)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3588 (0.4709)  time: 1.5253  data: 0.0004  max mem: 25280
[2026-01-27 04:59:39,012][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   200/625000]  eta: 11 days, 15:27:28  lr: 0.000033  min_lr: 0.000003  loss: 0.0197 (0.0201)  local_pts_loss: 0.0132 (0.0135)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0148 (0.0145)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5886 (0.4823)  time: 1.5024  data: 0.0003  max mem: 25280
[2026-01-27 05:00:39,721][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   240/625000]  eta: 11 days, 12:46:25  lr: 0.000033  min_lr: 0.000003  loss: 0.0180 (0.0202)  local_pts_loss: 0.0131 (0.0135)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0004 (0.0005)  rot_loss: 0.0142 (0.0146)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4437 (0.4941)  time: 1.5138  data: 0.0003  max mem: 25280
[2026-01-27 05:01:40,294][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   280/625000]  eta: 11 days, 10:45:53  lr: 0.000033  min_lr: 0.000003  loss: 0.0137 (0.0196)  local_pts_loss: 0.0117 (0.0134)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0005)  rot_loss: 0.0107 (0.0142)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2976 (0.4760)  time: 1.5294  data: 0.0004  max mem: 25280
[2026-01-27 05:02:43,024][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   320/625000]  eta: 11 days, 10:25:03  lr: 0.000033  min_lr: 0.000003  loss: 0.0139 (0.0190)  local_pts_loss: 0.0115 (0.0131)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0004)  rot_loss: 0.0109 (0.0141)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3821 (0.4662)  time: 1.5183  data: 0.0004  max mem: 25280
[2026-01-27 05:03:43,270][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   360/625000]  eta: 11 days, 8:57:01  lr: 0.000033  min_lr: 0.000003  loss: 0.0150 (0.0186)  local_pts_loss: 0.0118 (0.0130)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0004)  rot_loss: 0.0127 (0.0140)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3606 (0.4583)  time: 1.5024  data: 0.0004  max mem: 25280
[2026-01-27 05:04:44,217][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   400/625000]  eta: 11 days, 8:04:32  lr: 0.000033  min_lr: 0.000003  loss: 0.0137 (0.0182)  local_pts_loss: 0.0109 (0.0128)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0004)  rot_loss: 0.0123 (0.0140)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3760 (0.4500)  time: 1.4940  data: 0.0004  max mem: 25280
[2026-01-27 05:05:45,625][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   440/625000]  eta: 11 days, 7:32:15  lr: 0.000033  min_lr: 0.000003  loss: 0.0149 (0.0179)  local_pts_loss: 0.0119 (0.0127)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0004)  rot_loss: 0.0119 (0.0139)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4205 (0.4535)  time: 1.5534  data: 0.0004  max mem: 25280
[2026-01-27 05:06:47,252][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   480/625000]  eta: 11 days, 7:09:55  lr: 0.000033  min_lr: 0.000003  loss: 0.0151 (0.0177)  local_pts_loss: 0.0124 (0.0127)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0004)  rot_loss: 0.0112 (0.0138)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3290 (0.4494)  time: 1.5846  data: 0.0003  max mem: 25283
[2026-01-27 05:07:49,609][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   520/625000]  eta: 11 days, 7:05:25  lr: 0.000033  min_lr: 0.000003  loss: 0.0132 (0.0174)  local_pts_loss: 0.0108 (0.0126)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0099 (0.0136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2862 (0.4432)  time: 1.5633  data: 0.0004  max mem: 25283
[2026-01-27 05:08:49,370][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   560/625000]  eta: 11 days, 6:13:16  lr: 0.000033  min_lr: 0.000003  loss: 0.0143 (0.0173)  local_pts_loss: 0.0117 (0.0126)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0096 (0.0134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3288 (0.4418)  time: 1.5246  data: 0.0004  max mem: 25283
[2026-01-27 05:09:51,037][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   600/625000]  eta: 11 days, 6:00:56  lr: 0.000033  min_lr: 0.000003  loss: 0.0150 (0.0173)  local_pts_loss: 0.0120 (0.0126)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0132 (0.0135)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3786 (0.4396)  time: 1.5274  data: 0.0004  max mem: 25283
[2026-01-27 05:10:52,925][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   640/625000]  eta: 11 days, 5:53:35  lr: 0.000033  min_lr: 0.000003  loss: 0.0141 (0.0171)  local_pts_loss: 0.0112 (0.0125)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0118 (0.0134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4005 (0.4378)  time: 1.5099  data: 0.0004  max mem: 25283
[2026-01-27 05:11:53,832][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   680/625000]  eta: 11 days, 5:31:59  lr: 0.000033  min_lr: 0.000003  loss: 0.0139 (0.0170)  local_pts_loss: 0.0113 (0.0124)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0113 (0.0134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2965 (0.4385)  time: 1.5140  data: 0.0004  max mem: 25283
[2026-01-27 05:12:56,181][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   720/625000]  eta: 11 days, 5:33:30  lr: 0.000033  min_lr: 0.000003  loss: 0.0167 (0.0170)  local_pts_loss: 0.0127 (0.0124)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0142 (0.0134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3979 (0.4399)  time: 1.5443  data: 0.0004  max mem: 25283
[2026-01-27 05:13:57,900][utils.dist][INFO] - [rank: 0] Epoch: [29]  [   760/625000]  eta: 11 days, 5:26:06  lr: 0.000033  min_lr: 0.000003  loss: 0.0146 (0.0170)  local_pts_loss: 0.0117 (0.0125)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0096 (0.0133)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3940 (0.4401)  time: 1.5446  data: 0.0004  max mem: 25283
[2026-01-27 05:14:59,580][base_trainer_accelerate.py][INFO] - Start validation for epoch 29
[2026-01-27 05:15:05,347][utils.dist][INFO] - [rank: 0] Validation Epoch: [29]  [ 0/15]  eta: 0:01:26  loss: 0.0199 (0.0199)  local_pts_loss: 0.0137 (0.0137)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0100 (0.0100)  time: 5.7660  data: 2.6912  max mem: 25283
[2026-01-27 05:15:10,964][utils.dist][INFO] - [rank: 0] Validation Epoch: [29]  [14/15]  eta: 0:00:00  loss: 0.0199 (0.0199)  local_pts_loss: 0.0137 (0.0137)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0100 (0.0100)  time: 0.7588  data: 0.1796  max mem: 25283
[2026-01-27 05:15:11,241][utils.dist][INFO] - [rank: 0] Validation Epoch: [29] Total time: 0:00:11 (0.7773 s / it)
[2026-01-27 05:15:11,519][base_trainer_accelerate.py][INFO] - Validation results: loss: 0.0199 (0.0201)  local_pts_loss: 0.0137 (0.0137)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0100 (0.0100)
[2026-01-27 05:15:11,522][accelerate.accelerator][INFO] - Saving current state to /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model
[2026-01-27 05:15:15,933][accelerate.checkpointing][INFO] - Model weights saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/pytorch_model.bin
[2026-01-27 05:15:21,436][accelerate.checkpointing][INFO] - Optimizer state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/optimizer.bin
[2026-01-27 05:15:21,437][accelerate.checkpointing][INFO] - Scheduler state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/scheduler.bin
[2026-01-27 05:15:21,439][accelerate.checkpointing][INFO] - Random states saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/random_states_0.pkl
[2026-01-27 05:15:21,441][base_trainer_accelerate.py][INFO] - Saved best model at epoch 29 with val_metric: 0.0201
[2026-01-27 05:15:21,443][accelerate.accelerator][INFO] - Saving current state to /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29
[2026-01-27 05:15:25,806][accelerate.checkpointing][INFO] - Model weights saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/pytorch_model.bin
[2026-01-27 05:15:31,325][accelerate.checkpointing][INFO] - Optimizer state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/optimizer.bin
[2026-01-27 05:15:31,326][accelerate.checkpointing][INFO] - Scheduler state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/scheduler.bin
[2026-01-27 05:15:31,328][accelerate.checkpointing][INFO] - Random states saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/checkpoint_29/random_states_0.pkl
[2026-01-27 05:15:31,330][base_trainer_accelerate.py][INFO] - Saved state for global step 24000
[2026-01-27 05:15:33,439][base_trainer_accelerate.py][INFO] - Start training epoch 30, 800 iters per inner epoch. Training dtype bf16
[2026-01-27 05:15:48,398][utils.dist][INFO] - [rank: 0] Epoch: [30]  [     0/625000]  eta: 108 days, 4:32:17  lr: 0.000033  min_lr: 0.000003  loss: 0.0418 (0.0418)  local_pts_loss: 0.0169 (0.0169)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0023 (0.0023)  rot_loss: 0.0178 (0.0178)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.9030 (0.9030)  time: 14.9561  data: 12.6101  max mem: 24133
[2026-01-27 05:16:49,233][utils.dist][INFO] - [rank: 0] Epoch: [30]  [    40/625000]  eta: 13 days, 8:53:35  lr: 0.000033  min_lr: 0.000003  loss: 0.0183 (0.0203)  local_pts_loss: 0.0128 (0.0129)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0004 (0.0006)  rot_loss: 0.0125 (0.0138)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4504 (0.5333)  time: 1.5172  data: 0.0003  max mem: 25273
[2026-01-27 05:17:50,666][utils.dist][INFO] - [rank: 0] Epoch: [30]  [    80/625000]  eta: 12 days, 6:03:35  lr: 0.000033  min_lr: 0.000003  loss: 0.0154 (0.0195)  local_pts_loss: 0.0116 (0.0128)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0005)  rot_loss: 0.0106 (0.0136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4292 (0.5309)  time: 1.5207  data: 0.0004  max mem: 25273
[2026-01-27 05:18:51,582][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   120/625000]  eta: 11 days, 20:12:57  lr: 0.000033  min_lr: 0.000003  loss: 0.0146 (0.0181)  local_pts_loss: 0.0114 (0.0124)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0004)  rot_loss: 0.0122 (0.0136)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3517 (0.4901)  time: 1.5492  data: 0.0004  max mem: 25277
[2026-01-27 05:19:53,284][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   160/625000]  eta: 11 days, 16:06:09  lr: 0.000033  min_lr: 0.000003  loss: 0.0145 (0.0173)  local_pts_loss: 0.0125 (0.0123)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0004)  rot_loss: 0.0101 (0.0132)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4244 (0.4785)  time: 1.5337  data: 0.0004  max mem: 25282
[2026-01-27 05:20:54,089][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   200/625000]  eta: 11 days, 12:50:35  lr: 0.000032  min_lr: 0.000003  loss: 0.0147 (0.0174)  local_pts_loss: 0.0117 (0.0125)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0003 (0.0004)  rot_loss: 0.0107 (0.0134)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3209 (0.4844)  time: 1.5766  data: 0.0004  max mem: 25282
[2026-01-27 05:21:55,312][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   240/625000]  eta: 11 days, 10:57:42  lr: 0.000032  min_lr: 0.000003  loss: 0.0142 (0.0169)  local_pts_loss: 0.0110 (0.0122)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0113 (0.0132)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3247 (0.4676)  time: 1.5167  data: 0.0004  max mem: 25282
[2026-01-27 05:22:56,435][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   280/625000]  eta: 11 days, 9:33:00  lr: 0.000032  min_lr: 0.000003  loss: 0.0148 (0.0166)  local_pts_loss: 0.0112 (0.0120)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0127 (0.0130)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4179 (0.4649)  time: 1.5117  data: 0.0004  max mem: 25282
[2026-01-27 05:23:58,253][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   320/625000]  eta: 11 days, 8:51:40  lr: 0.000032  min_lr: 0.000003  loss: 0.0139 (0.0166)  local_pts_loss: 0.0114 (0.0120)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0110 (0.0131)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4065 (0.4635)  time: 1.5821  data: 0.0004  max mem: 25282
[2026-01-27 05:24:59,526][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   360/625000]  eta: 11 days, 8:03:34  lr: 0.000032  min_lr: 0.000003  loss: 0.0141 (0.0163)  local_pts_loss: 0.0112 (0.0119)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0097 (0.0128)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3917 (0.4583)  time: 1.5432  data: 0.0004  max mem: 25282
[2026-01-27 05:26:01,603][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   400/625000]  eta: 11 days, 7:45:43  lr: 0.000032  min_lr: 0.000003  loss: 0.0143 (0.0161)  local_pts_loss: 0.0113 (0.0118)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0112 (0.0126)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3998 (0.4518)  time: 1.5636  data: 0.0004  max mem: 25282
[2026-01-27 05:27:03,348][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   440/625000]  eta: 11 days, 7:23:06  lr: 0.000032  min_lr: 0.000003  loss: 0.0160 (0.0161)  local_pts_loss: 0.0120 (0.0118)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0003 (0.0003)  rot_loss: 0.0132 (0.0127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3969 (0.4527)  time: 1.5211  data: 0.0004  max mem: 25282
[2026-01-27 05:28:05,294][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   480/625000]  eta: 11 days, 7:08:24  lr: 0.000032  min_lr: 0.000003  loss: 0.0160 (0.0162)  local_pts_loss: 0.0125 (0.0119)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0102 (0.0127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3748 (0.4506)  time: 1.5509  data: 0.0004  max mem: 25282
[2026-01-27 05:29:07,517][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   520/625000]  eta: 11 days, 7:01:21  lr: 0.000032  min_lr: 0.000003  loss: 0.0142 (0.0161)  local_pts_loss: 0.0115 (0.0119)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0118 (0.0127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4092 (0.4496)  time: 1.5113  data: 0.0004  max mem: 25282
[2026-01-27 05:30:08,882][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   560/625000]  eta: 11 days, 6:39:14  lr: 0.000032  min_lr: 0.000003  loss: 0.0164 (0.0161)  local_pts_loss: 0.0116 (0.0118)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0003 (0.0003)  rot_loss: 0.0119 (0.0127)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.5254 (0.4523)  time: 1.5066  data: 0.0004  max mem: 25282
[2026-01-27 05:31:10,752][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   600/625000]  eta: 11 days, 6:28:41  lr: 0.000032  min_lr: 0.000003  loss: 0.0134 (0.0160)  local_pts_loss: 0.0109 (0.0118)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0109 (0.0126)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3683 (0.4463)  time: 1.5456  data: 0.0004  max mem: 25282
[2026-01-27 05:32:12,230][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   640/625000]  eta: 11 days, 6:12:56  lr: 0.000032  min_lr: 0.000003  loss: 0.0135 (0.0159)  local_pts_loss: 0.0120 (0.0118)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0085 (0.0124)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3283 (0.4439)  time: 1.5729  data: 0.0004  max mem: 25282
[2026-01-27 05:33:13,421][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   680/625000]  eta: 11 days, 5:54:33  lr: 0.000032  min_lr: 0.000003  loss: 0.0121 (0.0157)  local_pts_loss: 0.0103 (0.0117)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0086 (0.0125)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3353 (0.4422)  time: 1.5327  data: 0.0004  max mem: 25282
[2026-01-27 05:34:15,354][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   720/625000]  eta: 11 days, 5:48:49  lr: 0.000032  min_lr: 0.000003  loss: 0.0133 (0.0156)  local_pts_loss: 0.0106 (0.0117)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0124 (0.0125)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3765 (0.4423)  time: 1.5667  data: 0.0004  max mem: 25282
[2026-01-27 05:35:15,683][utils.dist][INFO] - [rank: 0] Epoch: [30]  [   760/625000]  eta: 11 days, 5:21:37  lr: 0.000032  min_lr: 0.000003  loss: 0.0128 (0.0156)  local_pts_loss: 0.0101 (0.0116)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0003)  rot_loss: 0.0093 (0.0125)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2876 (0.4383)  time: 1.5107  data: 0.0004  max mem: 25282
[2026-01-27 05:36:15,883][base_trainer_accelerate.py][INFO] - Start validation for epoch 30
[2026-01-27 05:36:21,532][utils.dist][INFO] - [rank: 0] Validation Epoch: [30]  [ 0/15]  eta: 0:01:24  loss: 0.0200 (0.0200)  local_pts_loss: 0.0129 (0.0129)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0173 (0.0173)  time: 5.6445  data: 3.8937  max mem: 25282
[2026-01-27 05:36:27,146][utils.dist][INFO] - [rank: 0] Validation Epoch: [30]  [14/15]  eta: 0:00:00  loss: 0.0200 (0.0200)  local_pts_loss: 0.0129 (0.0129)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0173 (0.0173)  time: 0.7505  data: 0.2598  max mem: 25282
[2026-01-27 05:36:27,420][utils.dist][INFO] - [rank: 0] Validation Epoch: [30] Total time: 0:00:11 (0.7689 s / it)
[2026-01-27 05:36:27,423][base_trainer_accelerate.py][INFO] - Validation results: loss: 0.0200 (0.0200)  local_pts_loss: 0.0129 (0.0129)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0005 (0.0005)  rot_loss: 0.0173 (0.0171)
[2026-01-27 05:36:27,426][accelerate.accelerator][INFO] - Saving current state to /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model
[2026-01-27 05:36:31,512][accelerate.checkpointing][INFO] - Model weights saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/pytorch_model.bin
[2026-01-27 05:36:36,829][accelerate.checkpointing][INFO] - Optimizer state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/optimizer.bin
[2026-01-27 05:36:36,831][accelerate.checkpointing][INFO] - Scheduler state saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/scheduler.bin
[2026-01-27 05:36:36,832][accelerate.checkpointing][INFO] - Random states saved in /mnt/localssd/Pi3_training/outputs/pi3_hospital_lowres/ckpts/best_model/random_states_0.pkl
[2026-01-27 05:36:36,834][base_trainer_accelerate.py][INFO] - Saved best model at epoch 30 with val_metric: 0.0200
[2026-01-27 05:36:38,937][base_trainer_accelerate.py][INFO] - Start training epoch 31, 800 iters per inner epoch. Training dtype bf16
[2026-01-27 05:36:53,829][utils.dist][INFO] - [rank: 0] Epoch: [31]  [     0/625000]  eta: 107 days, 17:03:21  lr: 0.000032  min_lr: 0.000003  loss: 0.0119 (0.0119)  local_pts_loss: 0.0106 (0.0106)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0001)  rot_loss: 0.0067 (0.0067)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.1822 (0.1822)  time: 14.8899  data: 11.0922  max mem: 24847
[2026-01-27 05:37:54,115][utils.dist][INFO] - [rank: 0] Epoch: [31]  [    40/625000]  eta: 13 days, 6:17:16  lr: 0.000032  min_lr: 0.000003  loss: 0.0141 (0.0155)  local_pts_loss: 0.0118 (0.0118)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0112 (0.0122)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3865 (0.4511)  time: 1.4958  data: 0.0004  max mem: 25266
[2026-01-27 05:38:54,805][utils.dist][INFO] - [rank: 0] Epoch: [31]  [    80/625000]  eta: 12 days, 3:09:08  lr: 0.000032  min_lr: 0.000003  loss: 0.0133 (0.0144)  local_pts_loss: 0.0109 (0.0113)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0082 (0.0109)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3782 (0.4193)  time: 1.5049  data: 0.0004  max mem: 25278
[2026-01-27 05:39:56,291][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   120/625000]  eta: 11 days, 19:05:15  lr: 0.000032  min_lr: 0.000003  loss: 0.0145 (0.0143)  local_pts_loss: 0.0117 (0.0112)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0002)  rot_loss: 0.0133 (0.0113)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3690 (0.4188)  time: 1.5250  data: 0.0003  max mem: 25278
[2026-01-27 05:40:56,721][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   160/625000]  eta: 11 days, 13:52:57  lr: 0.000032  min_lr: 0.000003  loss: 0.0150 (0.0151)  local_pts_loss: 0.0114 (0.0114)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0003 (0.0003)  rot_loss: 0.0105 (0.0119)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3765 (0.4380)  time: 1.5677  data: 0.0003  max mem: 25278
[2026-01-27 05:41:58,983][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   200/625000]  eta: 11 days, 12:19:27  lr: 0.000032  min_lr: 0.000003  loss: 0.0133 (0.0148)  local_pts_loss: 0.0109 (0.0112)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0114 (0.0118)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3583 (0.4239)  time: 1.6005  data: 0.0004  max mem: 25278
[2026-01-27 05:42:59,736][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   240/625000]  eta: 11 days, 10:11:28  lr: 0.000031  min_lr: 0.000003  loss: 0.0164 (0.0150)  local_pts_loss: 0.0124 (0.0113)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0114 (0.0120)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4348 (0.4331)  time: 1.5224  data: 0.0004  max mem: 25278
[2026-01-27 05:44:00,909][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   280/625000]  eta: 11 days, 8:55:11  lr: 0.000031  min_lr: 0.000003  loss: 0.0152 (0.0152)  local_pts_loss: 0.0118 (0.0114)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0003)  rot_loss: 0.0131 (0.0121)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.4741 (0.4448)  time: 1.5135  data: 0.0004  max mem: 25279
[2026-01-27 05:45:01,755][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   320/625000]  eta: 11 days, 7:47:05  lr: 0.000031  min_lr: 0.000003  loss: 0.0115 (0.0149)  local_pts_loss: 0.0096 (0.0112)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0105 (0.0120)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2513 (0.4289)  time: 1.5068  data: 0.0004  max mem: 25286
[2026-01-27 05:46:02,332][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   360/625000]  eta: 11 days, 6:46:03  lr: 0.000031  min_lr: 0.000003  loss: 0.0125 (0.0146)  local_pts_loss: 0.0103 (0.0111)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0110 (0.0118)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3663 (0.4193)  time: 1.5135  data: 0.0004  max mem: 25286
[2026-01-27 05:47:04,128][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   400/625000]  eta: 11 days, 6:28:41  lr: 0.000031  min_lr: 0.000003  loss: 0.0141 (0.0146)  local_pts_loss: 0.0108 (0.0111)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0002 (0.0002)  rot_loss: 0.0093 (0.0117)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3757 (0.4217)  time: 1.5173  data: 0.0004  max mem: 25286
[2026-01-27 05:48:05,992][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   440/625000]  eta: 11 days, 6:15:53  lr: 0.000031  min_lr: 0.000003  loss: 0.0120 (0.0144)  local_pts_loss: 0.0098 (0.0110)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0101 (0.0116)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3251 (0.4135)  time: 1.5258  data: 0.0004  max mem: 25286
[2026-01-27 05:49:07,340][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   480/625000]  eta: 11 days, 5:53:51  lr: 0.000031  min_lr: 0.000003  loss: 0.0116 (0.0142)  local_pts_loss: 0.0097 (0.0110)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0086 (0.0115)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.2614 (0.4087)  time: 1.5553  data: 0.0003  max mem: 25286
[2026-01-27 05:50:09,025][utils.dist][INFO] - [rank: 0] Epoch: [31]  [   520/625000]  eta: 11 days, 5:41:49  lr: 0.000031  min_lr: 0.000003  loss: 0.0125 (0.0141)  local_pts_loss: 0.0109 (0.0109)  normal_loss: 0.0000 (0.0000)  trans_loss: 0.0001 (0.0002)  rot_loss: 0.0091 (0.0114)  weight_decay: 0.0500 (0.0500)  grad_norm: 0.3839 (0.4076)  time: 1.5450  data: 0.0004  max mem: 25286
Traceback (most recent call last):
  File "/mnt/localssd/Pi3_training/scripts/train_pi3.py", line 13, in <module>
    main()
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/mnt/localssd/miniconda3/envs/py39/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/mnt/localssd/Pi3_training/scripts/train_pi3.py", line 10, in main
    trainer.train()
